---
layout: post
title: Blog Post 5
---

In this post, I'll write a tutorial on the topic of image classification and transfer learning.

Let's begin by importing all the libraries that we'll need in order to train our models and classify images in this tutorial. 


```python
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models
import matplotlib.pyplot as plt
import random
```

## Obtain Data

Now, let's access the data. We'll use a sample data set provided by the TensorFlow team that contains labeled images of cats and dogs.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 0s 0us/step
    68616192/68606236 [==============================] - 0s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


By running this code block, we have created TensorFlow `Dataset`s for training, validation, and testing. We can think of a `Dataset` as a pipeline that feeds data to a machine learning model. 

In our case, we've used a special-purpose `keras` utility that called `image_dataset_from_directory` to construct a `Dataset`. The most important argument is the first one, which says *where* the images are located. The `shuffle` argument says that, when retrieving data from this directory, the order should be randomized. The `batch_size` determines how many data points are gathered from the directory at once. Here, for example, each time we reqest some data we will get 32 images from each of the data sets. Finally, the `image_size` specifies the size of the input images.

The code in the next block is technical code related to rapidly reading data.


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

### Exploring Our Data Set

We can get a piece of a data set using the `take` method. For example, `train_dataset.take(1)` will retrieve one batch (32 images with labels) from the training data.

In the next cell, we'll write a function to create a two-row visualization. In the first row, we want to show three random pictures of cats. In the second row, we want to show three random pictures of dogs.


```python
def cats_dogs_pictures():

  # 2 classes of images
  class_names = ['cat', 'dog']

  # create a figure
  plt.figure(figsize=(10,6))
  # loop over one batch of the training data
  for images, labels in train_dataset.take(1):
    # initialize an empty list for cats
    cats = []
    # initialize an empty list for dogs
    dogs = []
    # loop over labels by indexing
    for i in range(32):
      # add the index to cats if the label is 0
      if class_names[labels[i]] == 'cat':
        cats.append(i)
      # add the index to dogs if the label is 1
      else:
        dogs.append(i)
    
    # choose three random elements from cats
    three_cats = random.sample(cats, 3)
    # choose three random elements from dogs
    three_dogs = random.sample(dogs, 3)
    # concatenate the two lists
    c_and_d = three_cats + three_dogs
        
    # loop over c_and_d by indexing
    for i in range(6):
      # add a subplot in a grid with 2 rows and 3 columns in position i+1
      ax = plt.subplot(2,3,i+1)
      # show the image
      plt.imshow(images[c_and_d[i]].numpy().astype("uint8"))
      # add a title
      plt.title(class_names[labels[c_and_d[i]]])
      # turn off the axes
      plt.axis("off")
```

Run the following line of code to show that our function works.


```python
cats_dogs_pictures() # demonstration
```


    
![cats-and-dogs.png](/images/cats-and-dogs.png)
    


### Check Label Frequencies

Let's compute the number of images in the training data with label `0` (corresponding to `"cat"`) and label `1` (corresponding to `"dog"`).


```python
# create an iterator called labels
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()

# initialize the number of pictures of cats
cat_count = 0
# initialize the number of pictures of dogs
dog_count = 0

# loop over the iterator
for label in labels_iterator:
  # add 1 to the number of pictures of cats if the image has label 0 
  if label == 0:
    cat_count += 1
  # add 1 to the number of pictures of dogs if the image has label 1
  else:
    dog_count += 1

# show the numbers
cat_count, dog_count
```




    (1000, 1000)



The *baseline* machine learning model is the model that always guesses the most frequent label. In our case, there is an equal number of images in the training data with label `0` and label `1`. So, the accuracy of the baseline model would be 50%. 

We'll treat this as the benchmark for improvement. Our models should do much better than this baseline model in order to be considered good data science achievements!

## First Model

Let's create a `tf.keras.models.Sequential` model using at least two `Conv2D` layers, at least two `MaxPooling2D` layers, at least one `Flatten` layers, at least one `Dense` layer, and at least one `Dropout` layer and give our model the name `model1`.


```python
# create a model
model1 = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.1),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(2) # number of classes
])
```

Now we can use the `model.summary()` to inspect our model.


```python
# show the summary
model1.summary()
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         
     )                                                               
                                                                     
     dropout (Dropout)           (None, 79, 79, 32)        0         
                                                                     
     conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     flatten (Flatten)           (None, 46208)             0         
                                                                     
     dense (Dense)               (None, 2)                 92418     
                                                                     
    =================================================================
    Total params: 102,562
    Trainable params: 102,562
    Non-trainable params: 0
    _________________________________________________________________


Let's train our model for 20 epochs and see how it does.


```python
# compile the model
model1.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# fit our model
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 65s 1s/step - loss: 56.6190 - accuracy: 0.4905 - val_loss: 0.6936 - val_accuracy: 0.5062
    Epoch 2/20
    63/63 [==============================] - 64s 1s/step - loss: 0.6881 - accuracy: 0.5360 - val_loss: 0.6940 - val_accuracy: 0.5111
    Epoch 3/20
    63/63 [==============================] - 65s 1s/step - loss: 0.6623 - accuracy: 0.5745 - val_loss: 0.7015 - val_accuracy: 0.5309
    Epoch 4/20
    63/63 [==============================] - 65s 1s/step - loss: 0.6137 - accuracy: 0.6280 - val_loss: 0.7525 - val_accuracy: 0.5248
    Epoch 5/20
    63/63 [==============================] - 65s 1s/step - loss: 0.5516 - accuracy: 0.6860 - val_loss: 0.7905 - val_accuracy: 0.5285
    Epoch 6/20
    63/63 [==============================] - 64s 1s/step - loss: 0.5123 - accuracy: 0.7140 - val_loss: 0.9471 - val_accuracy: 0.5483
    Epoch 7/20
    63/63 [==============================] - 65s 1s/step - loss: 0.4531 - accuracy: 0.7625 - val_loss: 1.1073 - val_accuracy: 0.5408
    Epoch 8/20
    63/63 [==============================] - 65s 1s/step - loss: 0.3970 - accuracy: 0.7985 - val_loss: 1.3729 - val_accuracy: 0.5520
    Epoch 9/20
    63/63 [==============================] - 65s 1s/step - loss: 0.3499 - accuracy: 0.8270 - val_loss: 1.8229 - val_accuracy: 0.5470
    Epoch 10/20
    63/63 [==============================] - 66s 1s/step - loss: 0.3341 - accuracy: 0.8445 - val_loss: 1.7864 - val_accuracy: 0.5557
    Epoch 11/20
    63/63 [==============================] - 65s 1s/step - loss: 0.3527 - accuracy: 0.8340 - val_loss: 2.2234 - val_accuracy: 0.5470
    Epoch 12/20
    63/63 [==============================] - 66s 1s/step - loss: 0.3121 - accuracy: 0.8590 - val_loss: 1.6453 - val_accuracy: 0.5693
    Epoch 13/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2962 - accuracy: 0.8645 - val_loss: 2.2887 - val_accuracy: 0.5520
    Epoch 14/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2882 - accuracy: 0.8670 - val_loss: 2.2020 - val_accuracy: 0.5507
    Epoch 15/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2492 - accuracy: 0.8820 - val_loss: 2.3942 - val_accuracy: 0.5421
    Epoch 16/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2285 - accuracy: 0.8860 - val_loss: 2.4319 - val_accuracy: 0.5495
    Epoch 17/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2043 - accuracy: 0.8995 - val_loss: 2.6207 - val_accuracy: 0.5507
    Epoch 18/20
    63/63 [==============================] - 66s 1s/step - loss: 0.1879 - accuracy: 0.9145 - val_loss: 2.8205 - val_accuracy: 0.5557
    Epoch 19/20
    63/63 [==============================] - 66s 1s/step - loss: 0.1811 - accuracy: 0.9170 - val_loss: 2.7909 - val_accuracy: 0.5532
    Epoch 20/20
    63/63 [==============================] - 65s 1s/step - loss: 0.2142 - accuracy: 0.9055 - val_loss: 2.6005 - val_accuracy: 0.5631


Next, we'll visualize the training history.


```python
# plot the history of the accuracy on the training set
plt.plot(history.history["accuracy"], label = "training")
# plot the history of the accuracy on the validation set
plt.plot(history.history["val_accuracy"], label = "validation")
# label the axes
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
# add a legend to the plot
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fb22faa6f10>




    
![first-model.png](/images/first-model.png)
    


Here's what we should note: 

1. **The validation accuracy of our model is between 52% and 57% during training.** In order to get the best validation accuracy we can, we include two `Conv2D` layers, two `MaxPooling2D` layers, one `Flatten` layer, one `Dense` layer, and one `Dropout` layer. 

2. We do a bit better than the baseline model. The accuracy of `model1` is 2% - 7% higher than the accuracy of the baseline model.

3. The training accuracy is much higher than the validation accuracy. So, we observe overfitting in `model1`.

## Model with Data Augmentation

Now we're going to add some *data augmentaion layers* to our model. Data augmentation refers to the practice of including modified copies of the same image in the training set. For example, a picture of a cat is still a picture of a cat even if we flip it upside down or rotate it 90 degrees. We can include such transformed versions of an image in our training process in order to help our model learn so-called *invariant* features of our input images.

First, we'll create a `tf.keras.layers.RandomFlip()` layer and make a plot of the original image and a few copies to which `RandomFlip()` has been applied.


```python
# create a RandomFlip() layer
flip = models.Sequential([
    layers.RandomFlip("horizontal_and_vertical")
])

# create a figure with three axes (1 row * 3 columns)
fig, ax= plt.subplots(1, 3, figsize=(8, 6))

# loop over one batch of the training data
for image, label in train_dataset.take(1):
  # choose the original image
  original_image = image[6]
  # plot the original image
  ax[0].imshow(original_image / 255.0)
  # turn off the first axis
  ax[0].axis("off")
  # add a title to the original image
  ax[0].set(title = "Original")

  # loop over the other two axes
  for i in range(1, 3):
    # flip the original image
    flip_image = flip(tf.expand_dims(original_image, 0))
    # plot two copies of the original image
    ax[i].imshow(flip_image[0] / 255.0)
    # turn off the other two axes
    ax[i].axis("off")
    # add titles to the two copies
    ax[i].set(title = "Flip " + str(i))
```


    
![random-flip.png](/images/random-flip.png)
    


Next, we'll create a `tf.keras.layers.RandomRotation()` layer and make a plot of both the original image and a few copies to which `RandomRotation` has been applied.


```python
# create a RandomRotation() layer
rotation = models.Sequential([
    layers.RandomRotation(0.3)
])

# create a figure with three axes (1 row * 3 columns)
fig, ax= plt.subplots(1, 3, figsize=(8, 6))

# loop over one batch of the training data
for image, label in train_dataset.take(1):
  # choose the original image
  original_image = image[8]
  # plot the original image
  ax[0].imshow(original_image / 255.0)
  # turn off the first axis
  ax[0].axis("off")
  # add a title to the first plot
  ax[0].set(title = "Original")

  # loop over the other two axes
  for i in range(1, 3):
    # rotate the original image
    rotation_image = rotation(tf.expand_dims(original_image, 0))
    # plot two copies of the original image
    ax[i].imshow(rotation_image[0] / 255.0)
    # turn off the other two axes
    ax[i].axis("off")
    # add titles to the two copies
    ax[i].set(title = "Rotation " + str(i))
```


    
![random-rotation.png](/images/random-rotation.png)
    


Now, let's create a new `tf.keras.models.Sequential` model called `model2` in which the first two layers are data augmentation layers. Use a `RandomFlip()` layer and a `RandomRotation()` layer.


```python
# create a model
model2 = models.Sequential([
    layers.RandomFlip('horizontal', input_shape=(160, 160, 3)),
    layers.RandomRotation(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.05),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.05),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(2) # number of classes
])
```

Now we can use the model.summary() to inspect our model.


```python
# show the summary
model2.summary()
```

    Model: "sequential_6"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     random_flip_1 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     random_rotation_4 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     conv2d_2 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_2 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     dropout_1 (Dropout)         (None, 79, 79, 32)        0         
                                                                     
     conv2d_3 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_3 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     dropout_2 (Dropout)         (None, 38, 38, 32)        0         
                                                                     
     conv2d_4 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                     
     max_pooling2d_4 (MaxPooling  (None, 18, 18, 64)       0         
     2D)                                                             
                                                                     
     conv2d_5 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                     
     max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         
     2D)                                                             
                                                                     
     conv2d_6 (Conv2D)           (None, 6, 6, 128)         73856     
                                                                     
     flatten_1 (Flatten)         (None, 4608)              0         
                                                                     
     dense_1 (Dense)             (None, 2)                 9218      
                                                                     
    =================================================================
    Total params: 148,642
    Trainable params: 148,642
    Non-trainable params: 0
    _________________________________________________________________


Let's train our model for 20 epochs and see how it does.


```python
# compile the model
model2.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# fit our model
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 86s 1s/step - loss: 0.6727 - accuracy: 0.5880 - val_loss: 0.6178 - val_accuracy: 0.6646
    Epoch 2/20
    63/63 [==============================] - 84s 1s/step - loss: 0.6461 - accuracy: 0.6215 - val_loss: 0.6556 - val_accuracy: 0.6101
    Epoch 3/20
    63/63 [==============================] - 84s 1s/step - loss: 0.6420 - accuracy: 0.6265 - val_loss: 0.6152 - val_accuracy: 0.6559
    Epoch 4/20
    63/63 [==============================] - 84s 1s/step - loss: 0.6346 - accuracy: 0.6505 - val_loss: 0.6357 - val_accuracy: 0.6337
    Epoch 5/20
    63/63 [==============================] - 83s 1s/step - loss: 0.6199 - accuracy: 0.6600 - val_loss: 0.6396 - val_accuracy: 0.6275
    Epoch 6/20
    63/63 [==============================] - 84s 1s/step - loss: 0.6123 - accuracy: 0.6740 - val_loss: 0.6326 - val_accuracy: 0.6510
    Epoch 7/20
    63/63 [==============================] - 84s 1s/step - loss: 0.6117 - accuracy: 0.6750 - val_loss: 0.6223 - val_accuracy: 0.6646
    Epoch 8/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5956 - accuracy: 0.6780 - val_loss: 0.6347 - val_accuracy: 0.6572
    Epoch 9/20
    63/63 [==============================] - 83s 1s/step - loss: 0.6124 - accuracy: 0.6715 - val_loss: 0.5772 - val_accuracy: 0.7054
    Epoch 10/20
    63/63 [==============================] - 83s 1s/step - loss: 0.6030 - accuracy: 0.6645 - val_loss: 0.5861 - val_accuracy: 0.6980
    Epoch 11/20
    63/63 [==============================] - 84s 1s/step - loss: 0.5949 - accuracy: 0.6860 - val_loss: 0.5950 - val_accuracy: 0.6782
    Epoch 12/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5767 - accuracy: 0.7025 - val_loss: 0.6064 - val_accuracy: 0.6671
    Epoch 13/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5831 - accuracy: 0.6845 - val_loss: 0.5649 - val_accuracy: 0.7191
    Epoch 14/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5623 - accuracy: 0.7115 - val_loss: 0.6897 - val_accuracy: 0.6312
    Epoch 15/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5951 - accuracy: 0.6750 - val_loss: 0.6414 - val_accuracy: 0.6448
    Epoch 16/20
    63/63 [==============================] - 82s 1s/step - loss: 0.5847 - accuracy: 0.6920 - val_loss: 0.6121 - val_accuracy: 0.6782
    Epoch 17/20
    63/63 [==============================] - 81s 1s/step - loss: 0.5736 - accuracy: 0.7040 - val_loss: 0.6038 - val_accuracy: 0.6733
    Epoch 18/20
    63/63 [==============================] - 82s 1s/step - loss: 0.5637 - accuracy: 0.7035 - val_loss: 0.5978 - val_accuracy: 0.6968
    Epoch 19/20
    63/63 [==============================] - 81s 1s/step - loss: 0.5621 - accuracy: 0.7060 - val_loss: 0.6277 - val_accuracy: 0.6522
    Epoch 20/20
    63/63 [==============================] - 82s 1s/step - loss: 0.5756 - accuracy: 0.7080 - val_loss: 0.5865 - val_accuracy: 0.6856


Next, we'll visualize the training history.


```python
# plot the history of the accuracy on the training set 
plt.plot(history.history["accuracy"], label = "training")
# plot the history of the accuracy on the validation set 
plt.plot(history.history["val_accuracy"], label = "validation")
# label the axes
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
# add a legend to the plot
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fb22f47c390>




    
![data-augmentation.png](/images/data-augmentation.png)
    


Here's what we should note:

1. **The accuracy of our model is between 63% and 70% during training.**

2. The validation accuracy of this model is about 10% higher than the accuracy we are able to obtain with `model1`.

3. We do not observe overfitting in `model2`.

## Data Preprocessing

The following code block will create a preprocessing layer called `preprocessor` which we can slot into our model pipeline.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

We can incorporate the `preprocessor` layer as the very first layer, before the data augmentation layers, and create a new `tf.keras.models.Sequential` model. Call the resulting model `model3`.


```python
# create a model
model3 = models.Sequential([
    preprocessor,                       
    layers.RandomFlip('horizontal', input_shape=(160, 160, 3)),
    layers.RandomRotation(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.05),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.05),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(2) # number of classes
])
```

Now we can use the model.summary() to inspect our model.


```python
# show the summary
model3.summary()
```

    Model: "sequential_7"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_flip_2 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     random_rotation_5 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     conv2d_7 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_6 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     dropout_3 (Dropout)         (None, 79, 79, 32)        0         
                                                                     
     conv2d_8 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_7 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     dropout_4 (Dropout)         (None, 38, 38, 32)        0         
                                                                     
     conv2d_9 (Conv2D)           (None, 36, 36, 64)        18496     
                                                                     
     max_pooling2d_8 (MaxPooling  (None, 18, 18, 64)       0         
     2D)                                                             
                                                                     
     conv2d_10 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                     
     max_pooling2d_9 (MaxPooling  (None, 8, 8, 64)         0         
     2D)                                                             
                                                                     
     conv2d_11 (Conv2D)          (None, 6, 6, 128)         73856     
                                                                     
     flatten_2 (Flatten)         (None, 4608)              0         
                                                                     
     dense_2 (Dense)             (None, 2)                 9218      
                                                                     
    =================================================================
    Total params: 148,642
    Trainable params: 148,642
    Non-trainable params: 0
    _________________________________________________________________


Let's train our model for 20 epochs and see how it does.


```python
# compile the model
model3.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# fit our model
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 85s 1s/step - loss: 0.6108 - accuracy: 0.6595 - val_loss: 0.5837 - val_accuracy: 0.6968
    Epoch 2/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5698 - accuracy: 0.6975 - val_loss: 0.6344 - val_accuracy: 0.6621
    Epoch 3/20
    63/63 [==============================] - 84s 1s/step - loss: 0.5549 - accuracy: 0.7130 - val_loss: 0.6766 - val_accuracy: 0.6547
    Epoch 4/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5602 - accuracy: 0.6900 - val_loss: 0.5519 - val_accuracy: 0.7153
    Epoch 5/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5531 - accuracy: 0.7185 - val_loss: 0.5555 - val_accuracy: 0.7017
    Epoch 6/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5437 - accuracy: 0.7240 - val_loss: 0.5747 - val_accuracy: 0.7067
    Epoch 7/20
    63/63 [==============================] - 82s 1s/step - loss: 0.5252 - accuracy: 0.7400 - val_loss: 0.5417 - val_accuracy: 0.7277
    Epoch 8/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5385 - accuracy: 0.7235 - val_loss: 0.5396 - val_accuracy: 0.7054
    Epoch 9/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5173 - accuracy: 0.7360 - val_loss: 0.5276 - val_accuracy: 0.7191
    Epoch 10/20
    63/63 [==============================] - 84s 1s/step - loss: 0.5161 - accuracy: 0.7415 - val_loss: 0.5510 - val_accuracy: 0.7240
    Epoch 11/20
    63/63 [==============================] - 83s 1s/step - loss: 0.5133 - accuracy: 0.7430 - val_loss: 0.5484 - val_accuracy: 0.7153
    Epoch 12/20
    63/63 [==============================] - 83s 1s/step - loss: 0.4971 - accuracy: 0.7440 - val_loss: 0.5015 - val_accuracy: 0.7525
    Epoch 13/20
    63/63 [==============================] - 83s 1s/step - loss: 0.4905 - accuracy: 0.7570 - val_loss: 0.5038 - val_accuracy: 0.7512
    Epoch 14/20
    63/63 [==============================] - 84s 1s/step - loss: 0.4735 - accuracy: 0.7730 - val_loss: 0.5255 - val_accuracy: 0.7401
    Epoch 15/20
    63/63 [==============================] - 83s 1s/step - loss: 0.4702 - accuracy: 0.7730 - val_loss: 0.5187 - val_accuracy: 0.7475
    Epoch 16/20
    63/63 [==============================] - 84s 1s/step - loss: 0.4728 - accuracy: 0.7765 - val_loss: 0.5099 - val_accuracy: 0.7450
    Epoch 17/20
    63/63 [==============================] - 83s 1s/step - loss: 0.4698 - accuracy: 0.7775 - val_loss: 0.4792 - val_accuracy: 0.7611
    Epoch 18/20
    63/63 [==============================] - 85s 1s/step - loss: 0.4367 - accuracy: 0.7985 - val_loss: 0.5073 - val_accuracy: 0.7587
    Epoch 19/20
    63/63 [==============================] - 84s 1s/step - loss: 0.4626 - accuracy: 0.7780 - val_loss: 0.5067 - val_accuracy: 0.7488
    Epoch 20/20
    63/63 [==============================] - 83s 1s/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4733 - val_accuracy: 0.7748


Next, we'll visualize the training history.


```python
# plot the history of the accuracy on the training set
plt.plot(history.history["accuracy"], label = "training")
# plot the history of the accuracy on the validation set
plt.plot(history.history["val_accuracy"], label = "validation")
# label the axes
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
# add a legend to the plot
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fb233bfb750>




    
![preprocessing.png](/images/preprocessing.png)
    


Here's what we should note:

1. **The validation accuracy of our model is between 70% and 76% during training.**

2. The validation accuracy of this model is about 20% higher than the accuracy we are able to obtain with `model1`.

3. We do not observe overfitting in `model3`.

## Transfer Learning

So far, we've been training models for distinguishing between cats and dogs from scratch. In some cases, however, someone might already have trained a model that does a related task, and might have learned some relevant patterns. For example, folks train machine learning models for a variety of image recognition tasks. Maybe we could use a pre-existing model for our task?

To do this, we need to first access a pre-existing "base model", incorporate it into a full model for our current task, and then train that model.

Run the following code block to download `MobileNetV2` and configure it as a layer that can be included in our model.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step


Now, let's create a `tf.keras.models.Sequential` model called `model4` that uses `MobileNetV2`. For this model, we'll use the following layers:

1. The `preprocessor` layer.

2. The data augmentation layers.

3. The `base_model_layer` constructed above.

4. A `GlobalMaxPooling2D` layer.

5. A `Dropout` layer.

6. A `Dense(2)` layer at the very end to actually perform the classification.


```python
# create a model
model4 = models.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal', input_shape=(160, 160, 3)),
    layers.RandomRotation(0.2),
    base_model_layer,
    layers.GlobalMaxPooling2D(),
    layers.Dropout(0.05),
    layers.Dense(2)
])
```

Now we can use the model.summary() to inspect our model.


```python
# show the summary
model4.summary()
```

    Model: "sequential_28"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_1 (Functional)        (None, 160, 160, 3)       0         
                                                                     
     random_flip_26 (RandomFlip)  (None, 160, 160, 3)      0         
                                                                     
     random_rotation_26 (RandomR  (None, 160, 160, 3)      0         
     otation)                                                        
                                                                     
     model_2 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d_6 (Glo  (None, 1280)             0         
     balMaxPooling2D)                                                
                                                                     
     dropout_46 (Dropout)        (None, 1280)              0         
                                                                     
     dense_26 (Dense)            (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________


Notice that we have 2562 parameters to train in the model.

Let's train our model for 20 epochs and see how it does.


```python
# compile the model
model4.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# fit our model
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 10s 102ms/step - loss: 0.8461 - accuracy: 0.7905 - val_loss: 0.1710 - val_accuracy: 0.9480
    Epoch 2/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.3238 - accuracy: 0.9010 - val_loss: 0.1037 - val_accuracy: 0.9641
    Epoch 3/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2533 - accuracy: 0.9280 - val_loss: 0.1004 - val_accuracy: 0.9641
    Epoch 4/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2151 - accuracy: 0.9375 - val_loss: 0.1057 - val_accuracy: 0.9678
    Epoch 5/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.1868 - accuracy: 0.9375 - val_loss: 0.0730 - val_accuracy: 0.9740
    Epoch 6/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.1923 - accuracy: 0.9405 - val_loss: 0.1108 - val_accuracy: 0.9678
    Epoch 7/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1608 - accuracy: 0.9465 - val_loss: 0.0817 - val_accuracy: 0.9703
    Epoch 8/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.1474 - accuracy: 0.9530 - val_loss: 0.0622 - val_accuracy: 0.9790
    Epoch 9/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1600 - accuracy: 0.9470 - val_loss: 0.1097 - val_accuracy: 0.9715
    Epoch 10/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1691 - accuracy: 0.9480 - val_loss: 0.0742 - val_accuracy: 0.9790
    Epoch 11/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1502 - accuracy: 0.9500 - val_loss: 0.1051 - val_accuracy: 0.9703
    Epoch 12/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1693 - accuracy: 0.9375 - val_loss: 0.0503 - val_accuracy: 0.9802
    Epoch 13/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1300 - accuracy: 0.9580 - val_loss: 0.1345 - val_accuracy: 0.9616
    Epoch 14/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1640 - accuracy: 0.9485 - val_loss: 0.0678 - val_accuracy: 0.9814
    Epoch 15/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1442 - accuracy: 0.9545 - val_loss: 0.0653 - val_accuracy: 0.9790
    Epoch 16/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1400 - accuracy: 0.9560 - val_loss: 0.0727 - val_accuracy: 0.9777
    Epoch 17/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.2481 - accuracy: 0.9310 - val_loss: 0.1515 - val_accuracy: 0.9592
    Epoch 18/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1286 - accuracy: 0.9575 - val_loss: 0.0588 - val_accuracy: 0.9752
    Epoch 19/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1880 - accuracy: 0.9475 - val_loss: 0.0710 - val_accuracy: 0.9790
    Epoch 20/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1352 - accuracy: 0.9560 - val_loss: 0.0585 - val_accuracy: 0.9777


Next, we'll visualize the training history.


```python
# plot the history of the accuracy on the training set
plt.plot(history.history["accuracy"], label = "training")
# plot the history of the accuracy on the validation set
plt.plot(history.history["val_accuracy"], label = "validation")
# label the axes
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
# add a legend to the plot
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f0e4c8c2bd0>




    
![transfer-learning.png](/images/transfer-learning.png)
    


Here's what we should note:

1. **The validation accuracy of our model is between 95% and 98% during training**.

2. The validation accuracy of this model is about 40% higher than the accuracy we are able to obtain with `model1`.

3. We do not observe overfitting in `model4`.

## Score on Test Data

`model4` is our most performant model. Let's evaluate the accuracy of `model4` on the unseen `test_dataset`.


```python
# evaluate the most performant model on the test data set
loss, accuracy = model4.evaluate(test_dataset)
accuracy
```

    6/6 [==============================] - 1s 58ms/step - loss: 0.1252 - accuracy: 0.9635





    0.9635416865348816



Great! `model4` can achieve 96% accuracy on the test set.
