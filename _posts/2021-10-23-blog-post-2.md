---
layout: post
title: Blog Post 2
---

In this blog post, I'm going to make a super cool web scraper to answer the following question:

**What movies or TV shows share actors with my favorite movie or TV show?**

Here's a link to my project repository: 

**https://github.com/JiaaiShen/blog-post-2/**

## Initialize our project

1. Create a new GitHub repository and sync it with GitHub Desktop. This repository will house our scraper. **We should commit and push each time we make siginificant changes to our code.**


2. Open a terminal in the location of our repository on our laptop, and type:

    `conda activate PIC16B`

    `scrapy startproject IMDB_scraper`

    `cd IMDB_scraper`

    This will create quite a lot of files, but we don't really need to touch most of them.

## Tweak settings

Let's add the following line to the file `settings.py`:

`CLOSESPIDER_PAGECOUNT = 20`

This line prevents our scraper from downloading too much data while we're still testing things out. We'll remove this line later.

## Write our scraper

Create a file inside the `spiders` directory called `imdb_spider.py`. Add the following lines to the file:


```python
# to run
# scrapy crawl imdb_spider -o movies.csv

import scrapy

class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'

    start_urls = ['https://www.imdb.com/title/tt8962124/']
```

The entry of `start_urls` is the URL corresponding to our favorite movie or TV show. My favorite TV show is Emily in Paris. Its IMDB page is at:

`https://www.imdb.com/title/tt8962124/`

We'll implement three parsing methods for the `ImdbSpider` class.

### Implementation of `parse()`


```python
def parse(self, response):
        """
        This method should assume that we start on a movie page
        and then navigate to the Cast & crew page.
        It does not return any data.
        """

        # URL of the Cast & crew page
        full_credits = response.url + 'fullcredits/'

        # yield a request specifying the parse_full_credits() method 
        # should be called when we get to the Cast & crew page
        yield scrapy.Request(full_credits, callback = self.parse_full_credits)
```

This method works by constructing and yielding a `scrapy.Request` with the URL of the *Cast & crew* page. This page has URL of the form `<movie_url>fullcredits/`. Once the *Cast & crew* page is reached, the `parse_full_creidts()` method should be called. We specify this method in the `callback` argument to the yielded request.

### Implementation of `parse_full_credits()`


```python
def parse_full_credits(self, response):
        """
        This method should assume that we start on the Cast & crew page
        and then navigate to the page of each actor listed on the page. 
        Crew members are not included. 
        It does not return any data.
        """

        # create a list of relative paths, one for each actor
        paths = [a.attrib["href"] for a in response.css("td.primary_photo a")]

        # loop through the list of paths
        for path in paths:

            # URL of the page of each actor
            actor_page = response.urljoin(path)

            # yield a request specifying the parse_actor_page() method 
            # should be called when the actor's page is reached
            yield scrapy.Request(actor_page, callback = self.parse_actor_page)
```

To write this method, we need to construct and yield a `scrapy.Request` with the URL of the page of each actor listed on the *Cast & crew* page. We'll use a list comprehension and the `urljoin()` method from `response` to find the URL of the page of each actor. Once the actor's page is reached, the `parse_actor_page()` method should be called. We specify this method in the `callback` argument to the yielded request.

### Implementation of `parse_actor_page()`


```python
def parse_actor_page(self, response):
        """
        This method should assume that we start on the page of an actor.
        It should yield a dictionary with two key-value pairs, 
        one of which contains the name of the actor, 
        the other of which contains the name of a movie or TV show, 
        for each of the movies or TV shows on which the actor has worked.
        """

        # container of the name of the actor
        overview = response.css("div#name-overview-widget")

        # extract the name of the actor
        actor_name = overview.css("span.itemprop::text").get()

        # loop through the actor's Filmography section
        for film in response.css("div.filmo-row"):
            
            # extract the id of each movie or TV show
            category = film.css("::attr(id)").get()

            # choose the movies and TV shows in the Actor or Actress section
            if ("actor" in category) or ("actress" in category):
                
                # extract the name of each movie or TV show
                movie_or_TV_name = film.css("a::text").get()

                # yield data
                yield {"actor" : actor_name,
                       "movie_or_TV_name" : movie_or_TV_name}
```

This method works by parsing the page of an actor and yielding a dictionary with two key-value pairs, of the form `{"actor" : actor_name , "movie_or_TV_name" : movie_or_TV_name}`. We can use CSS selectors to obtain the name of the actor and the name of each movie or TV show on which the actor has worked. 

## Make our recommendations

Once our spider is fully and correctly written, we'll comment out the line

`CLOSESPIDER_PAGECOUNT = 20`

in the `settings.py` file. Then we can run the command 

`scrapy crawl imdb_spider -o results.csv`

to run our spider and save a CSV file called `results.csv`, with a column for actors' names and a column for the movies and TV shows on which they worked.

Next, we'll compute a sorted list with the top movies and TV shows that share actors with my favorite TV show.

Let's import the library that we'll need in order to obtain the list for Emily in Paris.


```python
import pandas as pd
```

Run the following cell to read the `results.csv` file into Python as a `pandas` data frame called `df`.


```python
df = pd.read_csv("blog-post-2/IMDB_scraper/results.csv")
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor</th>
      <th>movie_or_TV_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lily Collins</td>
      <td>Gilded Rage</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lily Collins</td>
      <td>Titan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lily Collins</td>
      <td>Halo of Stars</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Lily Collins</td>
      <td>Windfall</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Lily Collins</td>
      <td>Emily in Paris</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2075</th>
      <td>Philippine Leroy-Beaulieu</td>
      <td>Three Men and a Cradle</td>
    </tr>
    <tr>
      <th>2076</th>
      <td>Philippine Leroy-Beaulieu</td>
      <td>Black Sequence</td>
    </tr>
    <tr>
      <th>2077</th>
      <td>Philippine Leroy-Beaulieu</td>
      <td>Mistral's Daughter</td>
    </tr>
    <tr>
      <th>2078</th>
      <td>Philippine Leroy-Beaulieu</td>
      <td>Surprise Party</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>Philippine Leroy-Beaulieu</td>
      <td>Eden</td>
    </tr>
  </tbody>
</table>
<p>2080 rows × 2 columns</p>
</div>



`pandas` provides a number of handy methods for combining and reshaping our data. We can use them to show the list. 


```python
# compute numbers of shared actors
share = df.groupby(["movie_or_TV_name"])["actor"].aggregate(len)
# recover the columns using reset_index()
share = share.reset_index()
# label the columns appropriately
share = share.rename(columns = {"movie_or_TV_name" : "movie" , 
                                "actor" : "number of shared actors"})

# sort the number of shared actors column in descending order
share = share.sort_values(by = ["number of shared actors"], 
                          ascending = False, 
                          ignore_index = True)

# get the first 10 rows of the data frame
share.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movie</th>
      <th>number of shared actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Emily in Paris</td>
      <td>78</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Le juge est une femme</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Spiral</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Plus belle la vie</td>
      <td>8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Joséphine, ange gardien</td>
      <td>8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Research Unit</td>
      <td>7</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Avocats &amp; associés</td>
      <td>6</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Fais pas ci, fais pas ça</td>
      <td>6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Chronicles of the Sun</td>
      <td>5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Cordier and Son: Judge and Cop</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



Of course, Emily in Paris will "share" the most actors with itself. Le juge est une femme is the TV show that shares the most actors with Emily in Paris. 
